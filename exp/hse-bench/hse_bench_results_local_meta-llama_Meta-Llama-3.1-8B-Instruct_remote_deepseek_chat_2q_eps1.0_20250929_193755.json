{
  "experiment_info": {
    "model_name": "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "num_samples": 2,
    "epsilon": 1.0,
    "start_time": "2025-09-29T19:37:55.218127",
    "dataset": "HSE-bench"
  },
  "results": {
    "total_questions": 2,
    "local_alone_correct": 2,
    "non_private_cot_correct": 2,
    "old_phrase_dp_local_cot_correct": 1,
    "inferdpt_local_cot_correct": 1,
    "santext_local_cot_correct": 1,
    "purely_remote_correct": 2,
    "local_alone_answers": [
      {
        "question_idx": 0,
        "predicted": "A",
        "correct": "A",
        "is_correct": true
      },
      {
        "question_idx": 1,
        "predicted": "B",
        "correct": "B",
        "is_correct": true
      }
    ],
    "non_private_cot_answers": [
      {
        "question_idx": 0,
        "predicted": "A",
        "correct": "A",
        "is_correct": true
      },
      {
        "question_idx": 1,
        "predicted": "B",
        "correct": "B",
        "is_correct": true
      }
    ],
    "old_phrase_dp_local_cot_answers": [
      {
        "question_idx": 0,
        "predicted": "A",
        "correct": "A",
        "is_correct": true
      }
    ],
    "inferdpt_local_cot_answers": [
      {
        "question_idx": 0,
        "predicted": "A",
        "correct": "A",
        "is_correct": true
      }
    ],
    "santext_local_cot_answers": [
      {
        "question_idx": 0,
        "predicted": "A",
        "correct": "A",
        "is_correct": true
      }
    ],
    "purely_remote_answers": [
      {
        "question_idx": 0,
        "predicted": "A",
        "correct": "A",
        "is_correct": true
      },
      {
        "question_idx": 1,
        "predicted": "B",
        "correct": "B",
        "is_correct": true
      }
    ]
  }
}