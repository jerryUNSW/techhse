PRIV-QA: Privacy-Preserving Question Answering for Cloud Large
Language Models
Guangwei Li* , Yuansen Zhang* † , Yinggui Wang
Shoumeng Yan, Lei Wang, Tao Wei
Ant Group
{yunxuan.lgw,yuansen.zys}@antgroup.com

arXiv:2502.13564v1 [cs.CL] 19 Feb 2025

Abstract

User

The rapid development of large language
models (LLMs) is redefining the landscape of
human-computer interaction, and their integration into various user-service applications is
becoming increasingly prevalent. However,
transmitting user data to cloud-based LLMs
presents significant risks of data breaches and
unauthorized access to personal identification
information. In this paper, we propose a privacy
preservation pipeline for protecting privacy
and sensitive information during interactions
between users and LLMs in practical LLM
usage scenarios. We construct SensitiveQA, the
first privacy open-ended question-answering
dataset. It comprises 57k interactions in
Chinese and English, encompassing a diverse
range of user-sensitive information within the
conversations. Our proposed solution employs
a multi-stage strategy aimed at preemptively
securing user information while simultaneously
preserving the response quality of cloud-based
LLMs. Experimental validation underscores
our method’s efficacy in balancing privacy
protection with maintaining robust interaction
quality. The code and dataset are available at
https://github.com/ligw1998/PRIV-QA.

1

Private Data

(a) HIGH PRIVACY RISK

PRIV-QA

Private Data

(b) SAFE INTERACTIONS

Figure 1: When using cloud-based LLMs, users must
send queries to providers who can access their private
data. However, by integrating our plug-and-play PRIVQA framework, we can maximize privacy protection
while ensure high-quality responses.

risks of personal sensitive information leaks (Yao
et al., 2024; Das et al., 2024). Therefore, ensuring
the privacy and security of user data during the
interactions is essential.
Previous privacy-preserving techniques for
cloud API-based LLMs can be primarily divided
into two categories. Local Differential Privacy
(LDP) methods (Yue et al., 2021; Chen et al.,
2023b; Tong et al., 2023) sequentially substitute
tokens in the text with new ones using specific
mapping functions. However, these methods only
protect user queries and do not safeguard the
responses generated by the LLM. On the other
hand, text sanitization approaches (Kan et al.,
2023; Shen et al., 2024; Chen et al., 2023c) hide
the private entities in the query for anonymization.
However, they concentrate only on specific
domains or tasks and limit their adaptability to
general question-answering scenarios. In addition,
the none-privacy entities (for example, the world’s
richest man) may also leak private information.
In this paper, we introduce PRIV-QA to safeguard user PRIVacy during Question Answering
when interacting with cloud LLMs. First, we
construct SensitiveQA, the first bilingual general

Introduction

Large language models (LLMs) have marked
a significant advancement in natural language
understanding and generation, revolutionizing
various industries, from customer service to content
creation (OpenAI et al., 2024; Dubey et al., 2024;
Zhao et al., 2024). However, due to commercial
demands and the models’ enormous parameter
sizes, many companies deploy cutting-edge LLMs
on remote cloud infrastructures, offering services
exclusively through APIs (OpenAI et al., 2024;
Models, 2023). This requires users to transmit
data to these cloud-based models, increasing the
* Contributed Equally.
†

CLOUD LLM

Work done during internship at Ant Group.

1

privacy question-answering dataset, containing
over 57k interactions between users and cloud
LLMs in both Chinese and English. Each query
in SensitiveQA includes a background text rich in
personal sensitive information, followed by a final
question. Second, we propose a privacy-preserving
framework to prevent malicious attacks during
interactions with cloud-based LLMs. Specifically,
our framework incorporates a multi-stage text
sanitization pipeline that classifies each word or
token in a query into three distinct privacy and
importance levels and subsequently applies tailored
protection mechanisms to each term based on
its assigned level before being transmitted to
cloud-based LLMs. After obtaining the responses
from cloud LLMs, the recover module ensures
the restoration of sensitive information, corrects
potential reasoning or conclusion errors, and
delivers the final recovered response to the user.
Experiments on the SensitiveQA dataset demonstrate that PRIV-QA achieves recall rates of
89.40% and 73.01% in sensitive information
detection for English and Chinese, respectively.
Additionally, PRIV-QA can resist 85.83% of
extraction attacks while achieving the highest
scores (for example, a BLEU score of 0.563 in
English) for the recovery responses.
Our contributions are summarised as follows:
• We construct SensitiveQA, the first general
privacy question-answering dataset, containing 57k interactions between users and cloud
LLMs in either Chinese or English.
• We propose a privacy-preserving framework
comprising a multi-stage text sanitization
procedure to eliminate and restore sensitive
information during interactions.
• Experimental results demonstrate that PRIVQA outperforms all baselines in detecting
sensitive information and query protection
while also maintaining the highest utility of
user queries.

2

Related Work

2.1

Privacy Preserving Techniques

random noise into the dataset. Federated Learning
(Chen et al., 2023a; Yu et al., 2024; Zhang et al.,
2024) offers a local-cloud collaboration paradigm
without the need to send personal data to the central
server. Other approaches like Homomorphic
Encryption (Chen et al., 2022; Hao et al., 2022)
and Multi-Party Computation (MPC) (Goldreich,
1998; Dong et al., 2023) is time-consuming and
can hardly be applied in real-world scenarios.
2.2

Text Sanitization Approaches

For cloud models with only API provided, the
above approaches can be infeasible to implement.
Therefore, text sanitization techniques rise as an
effective method, which aims to identify and
eliminate sensitive information from the text.
(Chen et al., 2023b; Yue et al., 2021; Tong et al.,
2023) replace tokens selective in the text, however,
their methods are not focused on privacy attributes
and still lead to privacy leakage risks. (Chen et al.,
2023c) hide the private entities for anonymization
and seek private entities for de-anonymization.
However, they only focus on classification and
translation tasks, which can not be generalized to
other tasks. (Lin et al., 2024) uses Emoji to encrypt
the user inputs before sending them to LLM. (Kan
et al., 2023) utilizes a privacy filter module to
identify and replace the privacy information in
the text without obfuscating non-privacy entities.
In addition, they use the open-sourced model in
the filter module and can fail for long documents
without training. On the contrary, our method
is a multi-stage privacy-protecting framework for
general QA scenarios and our hide and recover
modules have been trained on corresponding tasks
to better align with the requirements.

3

SensitiveQA Dataset

In order to simulate real-world user interactions
with cloud-based LLMs, we construct a dataset
that encompasses a variety of dialogues that
contain personal privacy information. Typically,
an ordinary user query can be divided into two
components: background text and final question.
The background text can vary in length and form.
It may consist of previous chat dialogue, passages
retrieved from a local knowledge base, or complex
user-modified instructions. Final questions are generally connected to this background information. It
is important to note that both the background text
and the questions may contain personally sensitive

Privacy concerns have become a significant issue
for the broad adoption of LLMs, and a variety
of works have explored the privacy-preserving
techniques for LLMs (Yan et al., 2024; Edemacu
and Wu, 2024). Differential Privacy (DP) (Tong
et al., 2023; Utpala et al., 2023; Tang et al., 2024;
Duan et al., 2023) is widely adopted by adding
2

Dataset

Num

Privacy

QA

Lang

Alpaca
MSRA
CNN/Daily Mail
MedQA
HaS Synthetic
SensitiveQA

52000
50729
311672
46974
19703
57251

✗
✗
✔
✗
✔
✔

✔
✗
✗
✔
✗
✔

EN
CN
EN
CN&EN
CN&EN
CN&EN

evaluation of our proposed method in open-ended
question-answering scenarios.

4

Method

Most frontier LLMs, which companies and individual users widely use, are close-sourced,
including ChatGPT (OpenAI et al., 2024), QwenSeries (Yang et al., 2024), and Claude (Models,
2023). These LLMs are typically hosted on
remote cloud computing infrastructures and are
exclusively accessible through web interfaces
or APIs, rendering them a black box to users.
To mitigate privacy risks in cloud-based LLM
applications, a viable solution is to de-identify the
users’ queries before sending them to cloud LLMs
and post-processing the LLM’s responses to restore
the sensitive information.
Our proposed PRIV-QA framework comprises
two core components: (1) Hide Module H designed for de-identifying private information, and
(2) Recover Module R responsible for restoring
the original sensitive data. The overview and
mechanism of our framework are presented in
Figure 2 and Algorithm 1. This section elaborates
on the framework’s constituent elements and
elucidates their respective functionalities.

Table 1: A comparison between the SensitiveQA
Dataset with other public datasets.

information. Directly sending this information to
cloud LLMs may cause privacy issues.
In this paper, we focus on the general questionanswering task in both Chinese and English.
For Chinese, we collect news and wiki terms
in News Summarization1 , CLTS (Liu et al.,
2022), WikipediaCN (Foundation, 2025), and
randomly select 10200 background texts. For
English, we collect 4434 background texts from
a personal identification information dataset2 . For
each background text, we use OpenAI GPT-4o
(OpenAI et al., 2024) to generate a range of
questions, encompassing various tasks such as
information extraction, open-ended Q&A, and text
summarization. More details can be found in
Appendix A.
Table 1 presents a comparison between
SensitiveQA and currently available public
datasets. General instruction-tuning datasets
like Alpaca (Taori et al., 2023) lack sufficient
user-related privacy information. In addition,
news datasets such as CNN/Daily Mail (See
et al., 2017) and named entity recognition (NER)
datasets like MSRA (Levow, 2006) contain
background texts but do not have related questions
to form a comprehensive LLM query. On the
other hand, privacy-focused datasets employed in
prior research (Chen et al., 2023c) are tailored to
specific domains or tasks, thereby limiting their
adaptability to open-ended question-answering
scenarios. Therefore, SensitiveQA offers a dataset
that is both privacy-related and general enough to
be applied across a wide range of QA contexts.
By leveraging the SensitiveQA dataset, our
framework is trained to effectively safeguard user
queries while preserving the high-quality response
capabilities of LLMs. We conduct a comprehensive

4.1

Hide Module: Query Protection by
Privacy Level

We implement a multi-stage text sanitization
pipeline to protect sensitive information in user
queries. For a user query X, our hide module dynamically implements tailored protection
strategies based on the identified risk levels of
individual tokens. Specifically, we establish a
tri-level classification (High-Risk, Low-Risk, and
Key-Words in Figure 3) that evaluates each lexical
component based on its potential privacy implications and semantic importance. Distinct protection
mechanisms are then applied according to these
classifications. Following we provide a detailed
exposition of our pipeline and implementation.
Sensitive Information Detection For a general
user query X = T ⊕ Q, compromised of
background text T and a question Q, we define
words that contain personal privacy information
as High-Risk words S. Through reviewing the
General Data Protection Regulation (GDPR3 ), we
identify five categories of privacy information:

1

https://www.kaggle.com/datasets/sbhatti/newssummarization
2
https://www.kaggle.com/datasets/alejopaullier/piiexternal-dataset

3

3

https://eur-lex.europa.eu/eli/reg/2016/679/oj/eng

Hide Module

Recover Module

chunking

User Query

:

The weather station

Sensitive model

in Springfield issued a

Substitution model

Importance Model

Recover model

yellow thunderstorm
warning at 2 PM on July
29.
...
Question: What time
period ... in Springfield?

Important words

merging

Sensitive words:

Substitution word pairs:

(1) Springfield
(2) 2PM
(3) July 29
...

(1) (Springfield : Dover)
(2) (2PM : 4PM)
(3) (July 29 : August 15)
...

①

LOCAL
CLOUD LLM

②

Obfuscate

excluding

:

Sum artist Radio presence
the town of Dover a Oh
thunderstorm parse
AND 4PM command August 15.
...

③

Correct Response:

The potential for thunderstorm
activity in Springfield is throughout
the eight hours from 2PM to
10PM on July 29.

⑤

API / Web Request
Wrong Response:
The potential for thunderstorm activity in Dover is

...
Black Box Inference

throughout the six hours from 4 PM to 10PM on
August 15.

④

Figure 2: Workflow of our privacy-preserving framework. For a user query, the hide module performs sensitive
information detection and substitution. Then, we obfuscate the non-privacy text excluding certain important words.
The recover module obtains the LLM responses and restores the privacy information in the text.

Sensitive Words Substitution To protect the
privacy information in X, each word in the
sensitive word set S must be replaced with
a semantically similarity but entirely different
word to ensure user privacy. However, simply
substituting sensitive words with random words
or meaningless placeholders can severely disrupt
the sentence’s semantics and structure, leading to
incoherent or irrelevant responses from the cloud
LLMs. To address this, we utilize another model
SubM to generate a privacy-preserving substitute
pi for each sensitive word si . SubM ensures
that the substituted query remains semantically
coherent and structurally intact. The word pairs
(si : pi ) are then used to transform the original
query X into a privacy-protected version Xs =
Ts ⊕ Qs , where all user-sensitive information is
effectively concealed.
The training data for SubM is generated by
prompting GPT-4 (OpenAI et al., 2024), resulting
in a dataset of 55,000 samples. Further details on
the prompts used for this process can be found in
Appendix B.2.

The weather station in Springfield issued a yellow thunderstorm warning at 2 PM on July 29.
It is expected that some areas within the city will experience thunderstorm activity over the
next eight hours, with localized heavy thunder, brief intense rainfall, and strong winds of 6 to
8 on the Beaufort scale potentially accompanying the storms. Please take precautions!
Question: What time period is the potential for thunderstorm activity in Springfield?
High Risk: must be REPLACED.
Low Risk: should be OBFUSCATED.
Key words: better be MAINTAINED.

Figure 3: An example of tri-level classification to a
given user query.

(1) Name of an individual or group; (2) Dates
and times; (3) Locations and specific places; (4)
Personal information including phone numbers, id,
(email) addresses, titles, etc; (5) Sensitive numbers
(monetary values, measurements, percentages, etc).
We finetune a generative model SenM to detect
the sensitive words in X. Detailed prompts can be
found in Appendix B.1. To construct the training
data, we prompt GPT-4o (OpenAI et al., 2024)
to detect sensitive words for a given query. We
manually verify the generations and obtain 5000
samples for training.
However, directly processing the entire query
X with SenM can be challenging and lead to the
omission of sensitive words, particularly when the
background text T is extensive. To address this
issue, we segment X into smaller chunks, xi , each
constrained by a token limit. Each chunk xi is then
processed by SenM to produce a list of sensitive
words, si . Finally, we aggregate and deduplicate
the sensitive words identified across all chunks to
form a comprehensive set of sensitive words S.

None-Privacy Text Obfuscation To further protect the low-risk part in X, we follow (Tong
et al., 2023) to substitute partial tokens in this
part. Specifically, for a certain LLM with the
corresponding token set V. We first select a subset
of V , defined as Vsub with a size K. In addition,
we have a differential privacy mechanism scoring
function u and randomized mechanism M , For
each token ti in Vsub , where i = 1, 2, . . . , k, we
4

Algorithm 1 PRIV-QA Framework
Input: Background Text T , Question Q, Full
Query X = T ⊕ Q, Sensitivity Model SenM ,
Substitution Model SubM , Importance Model
ImpM , Recover Model RcvM ;
Output: Correct Response A;
1: Split X into n chunks X = x0 ⊕ x1 ... ⊕ xn ;
2: for each xi do
3:
Sensitive words si = SenM (xi );
4: end for
5: S = s0 ∪ s1 ... ∪ sn ;
6: Substitution Word Pairs P = SubM (S);
7: Use word pairs P to replace X into Xs =
Ts ⊕ Qs ;
8: Select important words I = ImpM (Ts , Qs );
9: (Optional) Obfuscate all tokens in Ts into Ts,o
excluding I, P ;
10: X ′ = Ts,o ⊕ Qs ;
11: Get LLM Responses A′ = LLM (X ′ );
12: Get Correct Responses A = R(X ′ , X, A′ );
13: return A

erroneous response. To address this, we employ a
generative LLM RcvM to restore the substituted
words pi back to the original words si and correct
the reasoning errors in R′ while keeping the overall
thought process intact. Afterward, we obtain the
final correct response R. More details for training
RcvM can be found in Appendix B.3.

5.1

Experiment Setup

Metrics. We adopt both metrics-based and
model-based evaluation to judge the quality of
responses from the LLM. We use BLEU (Papineni
et al., 2002), METEOR (Banerjee and Lavie,
2005), and ROUGE (Lin, 2004) metrics to
objectively measure the discrepancy between
the recovered responses and the ground-truth
answers, allowing us to evaluate the quality of
the final recovered responses. We define the
ground-truth answer as the LLM response without
any privacy protection. For each test sample, we
offer three ground-truth answers. In addition, since
Large Langauge models can perform human-like
judgment (Zheng et al., 2023), we perform modelbased evaluations to evaluate the generation quality
comprehensively. We choose OpenAI GPT-4o as a
subjective evaluator to determine which response
better addresses the user query and whether the
information provided is accurate and aligned with
the original query. For each (recovered response,
ground-truth) pair, GPT-4o will give a win/tie/lose
judgment. To ensure reliability, we manually verify
the evaluation results and confirm that they align
with human judgment in over 90% of the cases.
Detailed prompts can be found in Appendix F.

(1)

where d is a distance function. For inference, we
randomly select a token from CW (ti ) and replace
ti in the text.
Impotrant Words Preservation Certain words
play a crucial role in understanding the text and
generating an appropriate response to the question.
For example, in medical diagnosis scenarios,
obscuring privacy-sensitive terms such as disease
could lead to inaccurate diagnostic outcomes. To
address this, we employ a model ImpM to identify
and preserve such critical terms, ensuring they
remain unobfuscated.
4.2

Experiments

Evaluation Setup and Test Set. The proposed
PRIV-QA is a bilingual framework supporting
both Chinese and English, enabling users to interact
with multiple cloud LLMs securely. We conduct
evaluations for these two languages independently.
We employ the SensitiveQA dataset for both
training and evaluation purposes. To comprehensively assess performance, we further partition the
test set into two distinct tasks: (1) information
extraction and (2) open-ended question answering.
The first task is designed to evaluate the model’s
capability in identifying sensitive information,
while the second task measures the impact of our
PRIV-QA framework on the response quality of
cloud-based large language models (LLMs).

compute a random adjacency CW (ti ) based on
the utility and privacy principles. Specifically, we
obtain corresponding embedding embi for ti and
add noise following the Laplace mechanism and
ˆ i . Then for each token in V and with its
obtain emb
embedding emb, we add it to CW (ti ) if it satisfies
ˆ i)
d(emb, embi ) ≤ d(embi , emb

5

Recover Module: Cloud Response
Correction

The sanitized query X ′ is securely transmitted
to cloud-based LLMs, yielding a response R′ .
However, due to the substitution and obfuscation
applied to the query, some information in R′ is
incorrect, resulting in a wrong reasoning chain and
5

SensitiveQA

SensitiveQA
EN
Precision Recall

EN
EDR(%)↑ BLEU↓

CN
Precision Recall

DeBERT
HaS

74.13
61.78

72.70
39.88

37.09
50.28

19.59
60.63

PRIV-QA SenM

91.36

89.40

78.99

73.01

Table 2: Results for sensitive information detection. We
provide precision and recall for three methods. The best
results are bolded.

CUSTEXT+
SANTEXT+
HaS

29.71
37.67
73.84

0.1955
0.3199
0.9310

53.30
23.79
75.54

0.1617
0.0269
0.7468

PRIV-QA w/o Obf
PRIV-QA w/ Obf

81.74
85.83

0.9336
0.0371

94.75
95.24

0.7753
0.5632

Table 3: Results for query protection. We report EDR
(Extraction Defense Rate) and BLUE for each method.
w/o Obf refers to results without our non-privacy text
obfuscation method. The best results are bolded.

Implementation. We choose the open-source
Qwen2-Chat (Yang et al., 2024) model as our
base model because of its relatively lightweight and
strong performance in both Chinese and English.
We choose Qwen2-0.5B-Chat for SenM , SubM
and ImpM , and Qwen2-1.5B-Chat for RecM . In
addition, for cloud-based LLM, we select GPT-4turbo 4 and Qwen-Plus 5 . For token adjacency
generation, we follow (Tong et al., 2023) to
generate OpenAI GPT-4-turbo token adjacency
utilizing text-embedding-ada-002 6 APIs. For
Qwen-Plus, we utilize Qwen2-7B-Chat for token
adjacency generation. More details can be found
in Appendix D.
5.2

CN
EDR(%)↑ BLEU↓

superior performance compared to previous methods in both precision and recall metrics. This
indicates its enhanced capability to accurately
identify sensitive words within queries in complex
real-world scenarios.
The Query Protection Performance. We evaluate query protection performance using two
metrics: (1) Extraction Defense Rate (EDR) and
(2) BLEU score between the protected query and
the original input query. As outlined in Section 5.1,
our test set comprises two tasks. Here, we leverage
the information extraction task to simulate potential
attacks from cloud LLM providers. For each
sample, both the original query and its protected
counterpart are paired with the same sensitive word
extraction question. The cloud LLM generates
respective sets of extracted results based on the
extraction queries. We assess whether the two
extracted results are consistent. If the cloud LLM
extracts inconsistent words from the protected
query, the protection is deemed successful. The
Extraction Defense Rate (EDR) is calculated as
the average defense success rate across all test
queries, with a higher EDR indicating superior
query protection performance. Additionally, we
use the BLEU score as a supplementary metric to
evaluate structural and semantic similarity.
We compare the query protection performance
of our PRIV-QA framework with local text
sanitization methods, including CUSTEXT+ (Chen
et al., 2023b), SANTEXT+ (Yue et al., 2021), and
the word substitution approach from HaS (Chen
et al., 2023c). As demonstrated in Table 3, PRIVQA achieves the highest EDR in both English and
Chinese, underscoring its superior query protection
capabilities. Furthermore, our non-privacy text
obfuscation process provides enhanced protection
by making the query unreadable to humans, as

Results

In order to do a comprehensive observation of
the framework performance in each stage, we
evaluate our proposed method from three aspects:
(1) Sensitive information detection performance;
(2) The overall level of protection for the processed
query transmitted to the cloud; (3) The utility,
correctness, and quality of the response.
Sensitive Information Detection Performance.
Correctly identifying the sensitive and privacyrelated information in the user query is a prerequisite for successfully protecting the query. We
compare our sensitive detection model SenM with
Hide-and-Seek (HaS) (Chen et al., 2023c), which
uses a combination of spaCy 7 and ltp 8 . We also
utilize another finetuned DeBERT-based model as
a fundamental baseline.
We construct a test set for evaluation following
the same prompts in Appendix B.1. As shown
in Table 2, our sensitive detection model achieves
4

https://platform.openai.com/docs/models/o1
https://bailian.console.aliyun.com/#/home
6
https://openai.com/index/new-and-improvedembedding-model/
7
https://github.com/explosion/spaCy
8
https://github.com/HIT-SCIR/ltp
5

6

BLEU

English
METEOR R-1

R-2

R-L

BLEU

Chinese
METEOR
R-1

R-2

R-L

GPT-4-turbo
CUSTEXT+
SANTEXT+
HaS

0.377
0.397
0.241

0.622
0.595
0.407

0.644
0.610
0.352

0.459
0.422
0.256

0.624
0.592
0.340

0.204
0.233
0.126

0.325
0.364
0.283

0.391
0.447
0.286

0.224
0.273
0.158

0.342
0.389
0.227

PRIV-QA w/o Obf
PRIV-QA w/ Obf

0.641
0.563

0.820
0.766

0.805
0.762

0.678
0.623

0.792
0.747

0.707
-

0.792
-

0.796
-

0.662
-

0.734
-

Qwen-Plus
CUSTEXT+
SANTEXT+
HaS

0.271
0.466
0.460

0.540
0.689
0.641

0.521
0.669
0.590

0.306
0.493
0.470

0.483
0.637
0.570

0.232
0.340
0.105

0.402
0.511
0.253

0.442
0.553
0.266

0.227
0.323
0.122

0.346
0.442
0.193

PRIV-QA w/o Obf
PRIV-QA w/ Obf

0.603
0.521

0.798
0.744

0.792
0.733

0.673
0.599

0.779
0.720

0.596
0.510

0.727
0.674

0.722
0.677

0.579
0.515

0.651
0.599

Table 4: Results for the recovery quality. We report BLUE, METEOR, ROUGE-1, ROUGE-2 and ROUGE-L for
each baseline method. We select GPT-4-turbo and Qwen-plus as our cloud models. For GPT-4-turbo, the Chinese
result for PRIV-QA w/ Obf is not reported due to the lack of open-source support for Chinese tokens in (Tong
et al., 2023). The best results are bolded, and the second best ones are underlined (for prompting method).

evidenced by the lower BLEU scores. However,
the higher protection does not lead to performance
degradation compared with baseline methods as
evidenced in Table 4. In contrast, CUSTEXT+
and SANTEXT+ exhibit lower EDR and higher
BLEU scores, indicating their ineffectiveness in
safeguarding sensitive entities.

SANTEXT+ perform better than HaS but still lag
significantly behind PRIV-QA. Additionally, our
non-privacy text obfuscation methods provide a
stronger defense against extraction attacks (Table 3), but result in a decline in slight response
quality, such as a drop of 0.078 BLUE points for
GPT-4-turbo in English.
The model-based evaluation by GPT-4o is
presented in Figure 4. We report the sum of
win and tie rates as positive rates. According to
Figure 4, PRIV-QA with text obfuscation achieves
a 74.49% positive rate in English and 68.17% in
Chinese, greatly surpassing previous methods and
indicating higher response quality.

Recovery Quality. We assess the quality of the
final recovered responses using both metrics-based
and model-based evaluation methods, as detailed
in Section 5.1. Our approach is compared against
CUSTEXT+ (Chen et al., 2023b), SANTEXT+
(Yue et al., 2021), and HaS (Chen et al., 2023c). For
CUSTEXT+ and SANTEXT+, the responses are
directly obtained from the cloud LLM, whereas for
HaS, the responses are generated by its seek model,
adhering to the hyper-parameters specified in its
original paper. We do not compare with (Kan et al.,
2023) as the methodology proposed in their work
closely resembles HAS, and neither their model
nor code has been made publicly available.
The metrics-based results are shown in Table 4.
We can figure out that PRIV-QA outperforms
previous methods on all metrics both in English
and Chinese. For instance, PRIV-QA achieves
BLUE scores of 0.641 and 0.603 for GPT-4-turbo
and Qwen-plus, respectively, surpassing HaS by
0.4 and 0.143 points. This could be because
HaS is task-specific (only for summarization
and translation tasks) and, therefore, struggles
in the general QA scenarios. CUSTEXT+ and

Trade-off between Security and Quality. Generally speaking, a higher security leads to a
lower final response quality since the processed
query is more challenging to understand, and the
recovery process is also more difficult. Under openended question-answering scenarios, we further
investigate the security and the final response
quality trade-off of each method in Figure 5. With
none-privacy text obfuscation, PRIV-QA achieves
higher query protection with a minor sacrifice in
recovered response quality. Notably, all configurations of PRIV-QA demonstrate a substantial
overall improvement over prior methods.
The Time Consumption of PRIV-QA To evaluate the efficiency of PRIV-QA, we conducted
a comparative analysis of time consumption with
and without the framework under varying input and
7

English

Chinese

CUSTEXT+
vs. GT

31.12%

68.88%

16.94%

83.06%

SANTEXT+
vs. GT

41.23%

68.88%

30.79%

69.21%

Hide-and-Seek
vs. GT

27.33%

72.67%

94.97%

PRIV-QA w/o
vs. GT

81.15%

18.85%

78.56%

21.44%

PRIV-QA w/
vs. GT

74.49%

25.51%

68.17%

31.83%

Win

Tie

Lose

PRIV-QA

Percentage of Time (%)

Response Quality (Win&Tie-Lose Rate %)

Figure 4: Final response quality results for each method compared to ground truth. GPT-4o is selected as the
win-tie-lose judge. We report the win&tie rate and lose rate.

PRIV-QA

English

Chinese

60.32%

36.41%
28.91%

31.95%

30.73%

30.89%

31.89%

TokenNum (Output + Input)

Query Protection (EDR %)

Figure 6: Proportion of time consumption per module in
PRIV-QA (deployed locally on one A800 GPU) across
different Input + Output token lengths.

Figure 5: Trade-off between query protection and
final response quality. The x-axis refers to the EDR
(Extraction Defense Rate), and the y-axis refers to the
win&tie rate against ground truth judged by GPT-4o.
Top-right methods perform best.

that PRIV-QA offers a balanced trade-off between
privacy enhancement and processing efficiency.
While there is an inherent time overhead associated
with additional privacy safeguards, the framework
ensures that this overhead remains manageable
across diverse query sizes.

output token numbers.
As depicted in Figure 6, when the number of input and output tokens is relatively small, the PRIVQA framework introduces a time consumption
increase of approximately 60%. However, as the
token count increases, the relative time overhead
introduced by PRIV-QA diminishes, stabilizing
around 30%. This reduction occurs because
the fixed costs of classification and protection
are amortized over a larger number of tokens,
resulting in a more efficient processing per token.
Consequently, the framework scales effectively,
maintaining acceptable efficiency losses even as
query complexity grows. Appendix E provides
detailed time cost.
The steady decrease in time consumption proportion with increasing token numbers demonstrates

6

Conclusion

In this paper, we propose PRIV-QA to secure
user privacy during question answering when
interacting with cloud LLMs. For user queries,
we detect and substitute the high-risk sensitive
information within while obfuscating low-risk text.
For cloud LLM responses, we restore the privacy
information and generate final responses. In addition, we construct the first general privacy questionanswering dataset in both English and Chinese.
Experiments demonstrate the effectiveness of our
approach in privacy-preserving while maintaining
LLM response quality.
8

7

Limitations

Ye Dong, Wen jie Lu, Yancheng Zheng, Haoqi Wu,
Derun Zhao, Jin Tan, Zhicong Huang, Cheng Hong,
Tao Wei, and Wenguang Chen. 2023. Puma: Secure
inference of llama-7b in five minutes. Preprint,
arXiv:2307.12533.

In this paper, we focus on general questionanswering scenario. Experiments on more complex
tasks, such as mathematical reasoning, are not
explored. In addition, the models in our pipeline
are trained solely on the Qwen series models due
to their superior performance in both English and
Chinese. Finally, our pipeline is limited to English
and Chinese, and we leave experiments on other
languages for future work.

8

Haonan Duan, Adam Dziedzic, Nicolas Papernot, and
Franziska Boenisch. 2023. Flocks of stochastic
parrots: Differentially private prompt learning for
large language models. Preprint, arXiv:2305.15594.
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,
and Abhishek Kadian. 2024. The llama 3 herd of
models. Preprint, arXiv:2407.21783.

Ethical Considerations

Kennedy Edemacu and Xintao Wu. 2024. Privacy
preserving prompt engineering: A survey. Preprint,
arXiv:2404.06001.

The background text in the SensitiveQA dataset
constructed in our paper is all collected from opensourced data such as Wikipedia. Therefore, the
data may contain personal privacy information.
However, the goal of our work is to advance the
privacy-preserving research of LLM and our work
may have potential influence in this area.

Wikimedia Foundation. 2025. Wikimedia downloads.
Oded Goldreich. 1998. Secure multi-party computation.
Manuscript. Preliminary version, 78(110):1–108.
Meng Hao, Hongwei Li, Hanxiao Chen, Pengzhi Xing,
Guowen Xu, and Tianwei Zhang. 2022. Iron: Private
inference on transformers. Advances in neural
information processing systems, 35:15718–15731.

References
Satanjeev Banerjee and Alon Lavie. 2005. METEOR:
An automatic metric for MT evaluation with
improved correlation with human judgments. In
Proceedings of the ACL Workshop on Intrinsic
and Extrinsic Evaluation Measures for Machine
Translation and/or Summarization, pages 65–72,
Ann Arbor, Michigan. Association for Computational
Linguistics.

Zhigang Kan, Linbo Qiao, Hao Yu, Liwen Peng, Yifu
Gao, and Dongsheng Li. 2023. Protecting user
privacy in remote conversational systems: A privacypreserving framework based on text sanitization.
arXiv preprint arXiv:2306.08223.

Chaochao Chen, Xiaohua Feng, Jun Zhou, Jianwei
Yin, and Xiaolin Zheng. 2023a. Federated large
language model: A position paper. Preprint,
arXiv:2307.08925.

Gina-Anne Levow. 2006. The third international
Chinese language processing bakeoff: Word segmentation and named entity recognition. In Proceedings
of the Fifth SIGHAN Workshop on Chinese Language
Processing, pages 108–117, Sydney, Australia.
Association for Computational Linguistics.

Sai Chen, Fengran Mo, Yanhao Wang, Cen Chen, JianYun Nie, Chengyu Wang, and Jamie Cui. 2023b.
A customized text sanitization mechanism with
differential privacy. In Findings of the Association
for Computational Linguistics: ACL 2023, page
5747–5758. Association for Computational Linguistics.

Chin-Yew Lin. 2004. ROUGE: A package for automatic
evaluation of summaries. In Text Summarization
Branches Out, pages 74–81, Barcelona, Spain.
Association for Computational Linguistics.
Guo Lin, Wenyue Hua, and Yongfeng Zhang. 2024.
Emojicrypt: Prompt encryption for secure communication with large language models. Preprint,
arXiv:2402.05868.

Tianyu Chen, Hangbo Bao, Shaohan Huang, Li Dong,
Binxing Jiao, Daxin Jiang, Haoyi Zhou, Jianxin Li,
and Furu Wei. 2022. The-x: Privacy-preserving
transformer inference with homomorphic encryption.
Preprint, arXiv:2206.00216.

Xiaojun Liu, Shunan Zang, Chuang Zhang, Xiaojun
Chen, and Yangyang Ding. 2022.
Clts+: A
new chinese long text summarization dataset with
abstractive summaries. In International Conference
on Artificial Neural Networks, pages 73–84.

Yu Chen, Tingxin Li, Huiming Liu, and Yang Yu. 2023c.
Hide and seek (has): A lightweight framework
for prompt privacy protection. arXiv preprint
arXiv:2309.03057.

Claude Models. 2023.
Model card and
evaluations for claude models.
https:
//www-files.anthropic.com/production/
images/Model-Card-Claude-2.pdf. (Accessed
on: [insert date here]).

Badhan Chandra Das, M. Hadi Amini, and Yanzhao
Wu. 2024. Security and privacy challenges of
large language models: A survey.
Preprint,
arXiv:2402.00888.

9

OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal,
Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman,
Diogo Almeida, Janko Altenschmidt, and Sam
Altman. 2024. Gpt-4 technical report. Preprint,
arXiv:2303.08774.

Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin
Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang
Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren,
Xuejing Liu, Yang Fan, Yang Yao, Yichang Zhang,
Yu Wan, Yunfei Chu, Yuqiong Liu, Zeyu Cui, Zhenru
Zhang, Zhifang Guo, and Zhihao Fan. 2024. Qwen2
technical report. Preprint, arXiv:2407.10671.

Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic
evaluation of machine translation. In Proceedings
of the 40th annual meeting of the Association for
Computational Linguistics, pages 311–318.

Yifan Yao, Jinhao Duan, Kaidi Xu, Yuanfang Cai, Zhibo
Sun, and Yue Zhang. 2024. A survey on large
language model (llm) security and privacy: The good,
the bad, and the ugly. High-Confidence Computing,
4(2):100211.

Abigail See, Peter J. Liu, and Christopher D. Manning.
2017. Get to the point: Summarization with
pointer-generator networks. In Proceedings of
the 55th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers),
pages 1073–1083, Vancouver, Canada. Association
for Computational Linguistics.

Sixing Yu, J. Pablo Muñoz, and Ali Jannesari. 2024.
Federated foundation models: Privacy-preserving
and collaborative learning for large models. Preprint,
arXiv:2305.11414.
Xiang Yue, Minxin Du, Tianhao Wang, Yaliang
Li, Huan Sun, and Sherman SM Chow. 2021.
Differential privacy for text analytics via natural text
sanitization. arXiv preprint arXiv:2106.01221.

Zhili Shen, Zihang Xi, Ying He, Wei Tong, Jingyu Hua,
and Sheng Zhong. 2024. The fire thief is also the
keeper: Balancing usability and privacy in prompts.
arXiv preprint arXiv:2406.14318.

Jianyi Zhang, Saeed Vahidian, Martin Kuo, Chunyuan
Li, Ruiyi Zhang, Tong Yu, Yufan Zhou, Guoyin
Wang, and Yiran Chen. 2024. Towards building the
federated gpt: Federated instruction tuning. Preprint,
arXiv:2305.05644.

Xinyu Tang, Richard Shin, Huseyin A. Inan, Andre
Manoel, Fatemehsadat Mireshghallah, Zinan Lin,
Sivakanth Gopi, Janardhan Kulkarni, and Robert Sim.
2024. Privacy-preserving in-context learning with
differentially private few-shot generation. Preprint,
arXiv:2309.11765.

Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,
Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen
Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen
Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang,
Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu,
Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2024.
A survey of large language models. Preprint,
arXiv:2303.18223.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann
Dubois, Xuechen Li, Carlos Guestrin, Percy Liang,
and Tatsunori B. Hashimoto. 2023. Stanford alpaca:
An instruction-following llama model. https://
github.com/tatsu-lab/stanford_alpaca.
Meng Tong, Kejiang Chen, Yuang Qi, Jie Zhang,
Weiming Zhang, and Nenghai Yu. 2023. Privinfer:
Privacy-preserving inference for black-box large
language model. arXiv preprint arXiv:2310.12214.

Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan
Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,
Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang,
Joseph E. Gonzalez, and Ion Stoica. 2023. Judging
llm-as-a-judge with mt-bench and chatbot arena.
Preprint, arXiv:2306.05685.

Saiteja Utpala, Sara Hooker, and Pin-Yu Chen. 2023.
Locally differentially private document generation
using zero shot prompting. In Findings of the
Association for Computational Linguistics: EMNLP
2023, pages 8442–8457, Singapore. Association for
Computational Linguistics.

Appendices
A

Biwei Yan, Kun Li, Minghui Xu, Yueyan Dong,
Yue Zhang, Zhaochun Ren, and Xiuzhen Cheng.
2024. On protecting the data privacy of large
language models (llms): A survey. Preprint,
arXiv:2403.05156.

SensitiveQA Dataset Construction

As declared in Section 3, we collect 10200 and
4434 background text for English and Chinese,
respectively. For each background text, we
prompt GPT-4o to generate several questions,
encompassing various tasks such as information
extraction, open-ended Q&A, and text summarization. Each Chinese query comprises approximately
25 sensitive entities, while each English query
contains around 6 sensitive entities. In addition,
as discussed in 5.1, we divide general questionanswering into two tasks: open-ended questionanswering and information extraction. The prompt

An Yang, Baosong Yang, Binyuan Hui, Bo Zheng,
Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan
Li, Dayiheng Liu, Fei Huang, Guanting Dong,
Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang,
Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin
Ma, Jianxin Yang, Jin Xu, Jingren Zhou, Jinze Bai,
Jinzheng He, Junyang Lin, Kai Dang, Keming Lu,
Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue,
Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men,
Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan

10

models are fully finetuned using ms-swift 9
package and deepspeed for 5 epochs. The batch
size is 4 for each GPUs, and the learning rate is
1e-5. For inference, we set the temperature of cloud
LLM to 0.7.

for question generation can be found in Table 17.
The data distribution of our SensitiveQA dataset is
detailed in Table 5.
Text

Question

SPD

CN

EN

CN

EN

CN

EN

Train
Test

10000
200

4300
134

48903
1134

6448
766

24.55
24.92

5.74
5.71

Total

10200

4434

50037

7214

24.56

5.72

E

We report the time consumption of the complete
QA pipeline integrating our PRIV-QA in Figure 7.
In order to ensure a fair comparison and stable
results, we deploy a Qwen2-72B-Instruct model
locally on 4 A800 GPUs to simulate a cloud LLM
service. Our PRIV-QA is deployed jointly on
one A800 GPU. The recover module efficiency is
sensitive to the output token numbers while the rest
parts’ efficiency is more sensitive to input token
numbers. Results show that our PRIV-QA ensures
manageable time overhead.

Table 5: A Statistical Overview of the SensitiveQA
Dataset. SPD refers to Sensitive Entities per Data.

B

Training Dataset Construction

B.1

Prompts for Sensitive Words Generation

Total Time consumption

To train our sensitive detection models, we prompt
GPT-4o to extract sensitive words given a background text. We obtain 20k+ data in total. The
detailed prompts are shown in Table 6 and Table 7.

83.80s

68.19s

B.2 Prompts for Sensitive Words Substitution
Generation

53.02s
49.30s

To train our sensitive word substitution model, we
prompt GPT-4o to generate training data. We
obtain 57k+ data in total. The detailed prompts
are shown in Table 8 and Table 9.
B.3

30.89s

4.87s

Prompts for Recover Model Training
Data Generation

Figure 7: Total Time Cost of PRIV-QA (deployed
locally on one A800 GPU) pipeline across different
Input + Output token lengths.

We prompt GPT-4o to generate training data for
our recover model. We obtain 57k+ data in total.
Detailed prompts can be found in Table 10 and
Table 11.
B.4

32.86s

F

GPT-4 Judge Prompt

The prompts for GPT-4 Judge can be found in
Table 16.

Prompts for Importance Words
Generation

To train the important word extraction model, we
prompt GPT-4o to generate training data. We
obtain 20k+ data in total. Detailed prompts can
be found in Table 12 and Table 13.

C

Examples for Our Privacy-preserving
Pipeline

To qualitatively demonstrate the pipeline of our
method, we provide an example for English
Table 15 and Chinese Table 14, respectively.

D

Experimental Details

We run our experiments on three NVIDIA A100
GPUs for training and one for inference. All

9

11

https://github.com/modelscope/ms-swift

You are a privacy protection expert. Given a segment of text, you need to identify all the personal privacy-related information
from that text. The categories of privacy information include the following:
1. Personal or company names
2. Dates and times
3. Locations (specific locations such as countries, provinces, cities, counties, districts, towns, villages, streets, residences, etc.
must be clearly defined place names and should not include vague or generic location terms)
4. Personal information (phone numbers, identification details, email addresses, job titles, etc.)
5. Sensitive numbers (amounts of money, lengths, percentages, etc.)
Output requirements are as follows:
1. Each category should be output on a separate line, starting with the category name and followed by the specific terms
containing privacy information. If a category does not contain any information, output ’None’ for that category.
2. Each category should list terms in the order they appear in the text, with duplicate terms output only once.
3. For location-related terms, only specific place names should be included.
4. When outputting numbers, if there is a measure word after the number, it should be included with the number. For example,
’4 times’, ’6 years’
Here is a specific example:
Text:
My name is Shan Popova and I am an industrial engineer with seven years of experience. One of my past job-related projects
was a comprehensive analysis of the production process at a local manufacturing plant. The goal of this project was to identify
areas for improvement in terms of efficiency, cost reduction, and quality control. I spent several weeks at the plant, observing
the production process firsthand and collecting data on various aspects of the operation. I also interviewed employees at all
levels to gather their insights and suggestions. Based on my findings, I developed a detailed report outlining a number of
recommendations for improvement. These included changes to the layout of the production line, the implementation of new
technologies, and the adoption of best practices in quality control. I presented my report to the plant manager and his team, and
they were very receptive to my ideas. They immediately began implementing some of my recommendations, and within a few
months, they saw a significant improvement in their production efficiency and quality. I was very proud of the work I did on
this project, and it was a great learning experience for me. It also showed me the real-world impact that industrial engineers can
have on the success of a manufacturing business. Here are some of my contact details: * Phone:
(376) 290-1236 * Email: shanpopova@gmail.gov * Address: 2811 Battery Place Northwest I also enjoy visiting museums in
my free time.
Privacy-related information:
Personal or company names:Shan Popova
Dates and times:None
Locations:2811 Battery Place Northwest
Personal information:(376) 290-1236,shanpopova@gmail.gov
Sensitive numbers:seven years
Following the example above, find the private information in the following text without outputting additional examples.
Text:

Privacy-related information:

Table 6: Prompts for sensitive word generation in English.

12

你是一个隐私保护专家，给定一段文本，需要你从该文本中找出所有的和个人隐私有关的信息，隐私信息的类别主
要有下面几类：
1. 个人或者公司名字
2. 日期和时间
3. 地点（具体地点如国家，省份，市，县，区，镇，村，街道，住所等，必须是明确的地名，不得包括模糊或通用
性地点词汇）
4. 个人信息相关（电话，证件信息，电子邮件，职位等）
5. 敏感数字（金钱，长度，百分比等）
输出要求如下：
1. 每一类为一行进行输出，先输出类别的名称，后输出具体的包含隐私信息的词，如果不包含某类的信息，则该类
输出“无”。
2. 每一类按照词在文本中出现的先后顺序从前到后进行输出，相同的词只输出一次。
3. 地点类词汇只需标注具体的地名，不需要包含详细职位或单位名称。例如对于“湖北省省委组织部”，只需要输
出“湖北省”即可。
4. 输出数字的时候，如果数字后有量词，需要和量词一起输出。例如“4次”，“6年”。
下面是一个具体的示例：
文本：
胡荣(景泰进士)
胡荣（？），字希仁，号东洲，江西临江府新喻县人，军籍，明朝政治人物。进士出身。
生平
江西乡试第十七名。景泰五年（1454年），参加甲戌科会试，得贡士第三百四十五名。殿试登进士第二甲第四名。
历官户科给事中、广东按察司提学佥事，成化十一年四月升浙江提学副使。二十年五月复拜福建按察司副使，弘治
元年七月升广西右参政。著有《道器图》、《东洲稿》。
家族
曾祖父子固。祖父胡源远。父亲胡淳启。
隐私信息：
个人或者公司名字：胡荣，胡源远，胡淳启
日期和时间：景泰五年，1454年，成化十一年四月，二十年五月，弘治元年七月
地点：江西临江府新喻县，广东，浙江，福建，广西
个人信息相关：无
敏感数字：第十七名，第三百四十五名，第二甲第四名
仿照上面的示例，找出下列文本中的隐私信息，不要输出额外的信息。
文本：
隐私信息：

Table 7: Prompts for sensitive word generation in Chinese.

You are an expert responsible for protecting the privacy information in the given text. Please strictly replace the specified words
in the provided text (including several questions) with corresponding similar words (the meaning of the replaced words should
differ from the original). Ensure that the modified text is coherent and flows smoothly, while maximizing the protection of the
privacy information contained in the original words. Only provide the pairs of replaced words in the format ’(a:b),(c:d),(e:f)’,
with each pair separated by a comma.
Given text:
Words to be replaced:
Pairs of replaced words:

Table 8: Prompts for substitution word generation in English.

13

你是一位负责保护给定文本的隐私信息的专家，请严格根据需要替换的词，将给定的文本（包括数个问题）中的这
些词替换成对应的同类其他词（替换后词与原词含义不同），保证替换后的文本语义流畅通顺，且最大可能保护原
词中含有的隐私信息，只需要给出替换前后的词对，用(a:b)代表一对替换前后的词，每两对之间用’,’隔开。
以下是一个替换示例：给定的文本：#西安体育学院#西安(Xi’an)体育学院青年教师王杨在世界级大金属掷球锦标
赛中勇夺两金。2016年第十届世界女子大金属掷球锦标赛于10月1日至8日在摩洛哥卡萨布兰卡举行,来自四大洲
的22个国家参加了比赛。在为期5天的比赛中,由我院网地教研室教师高卫任主教练的中国女队团结向上,顽强拼
搏,力克各路高手,取得了四金一银的历史最好成绩。图文by西安体院，10月25日13:00。问1：2016年第十届世界女
子大金属掷球锦标赛在哪个国家举行的？
需要替换的词：西安,Xi’an,王杨,2016年,第十届,10月1日至8日,摩洛哥,卡萨布兰卡,四大洲,22个国家,5天,网地教研
室,高卫,中国,四金一银,10月25日,13:00
替换前后的词对：(西安:西京),(Xi’an:Xijing),(王杨:李刚),(2016年:2015年),(第十届:第三届),(10月1日至8日:11月12日
至19日),(摩洛哥:突尼斯),(卡萨布兰卡:突尼斯城),(四大洲:五大洲),(22个国家:18个国家),(5天:8天),(网地教研室:田径
教研室),(高卫:张华),(中国:亚洲),(四金一银,五金一铜),(10月25日:11月1日),(13:00:17:15)
参考上述示例，现在给定文本：
需要替换的词：
替换前后的词对：

Table 9: Prompts for substitution word generation in Chinese.
Below is a piece of text, followed by several questions related to the text, along with the corresponding answers:
Text:
Question:
Corresponding Answer:
However, due to privacy and security considerations, certain concepts or text in this document have been replaced. The real text
and the question are as follows:
Real text:
Real Question:
Could you please rewrite the above responses based on real news reports and questions, modifying the concepts and text in the
answers so that the revised responses align with the information in the actual texts? Please make as few changes to the structure
and format of the original responses as possible. If the original answer is completely incorrect, provide a new answer. If the
information in the original response is entirely correct, no changes are needed. Present the revised answers in the following
format (using three answers as an example): ’Answer 1: Revised answer 1
Answer 2: Revised answer 2
Answer 3: Revised answer 3’. Only provide the revised answers.

Table 10: Prompts for recover model training data generation in English.

以下是一段文本，针对文本有数个问题，以及对应的问题回答：
文本：
问题：
对应的回答：
但由于隐私与安全考虑，该文本与问题中的某些概念或文本已经经过了替换，真实的文本与问题如下：
真实的文本：
真实的问题：
你能否根据真实的新闻报道与问题，将上述回答进行改写，修改回答中的概念与文本使得修改后的回答符合真实文
本中的信息，同时尽可能少地修改上述回答的结构与回答方式，如果原本的回答完全错误，则重新进行回答，如果
原本的回答中的信息完全正确，则可以不进行修改，将修改后回答（以五个回答为例）以’答1：修改后的回答1
答2：修改后的回答2
答3：修改后的回答3
答4：修改后的回答4
答5：修改后的回答5’这样的形式给出，只需要给出修改后的回答。

Table 11: Prompts for recover model training data generation in Chinese.

14

Extract the most important words from the given context text to answer the question (select as few and important words as
possible) without providing an answer to the question. The output words are separated by ’,’.
Text:
Question:
Important words:

Table 12: Prompts for important word generation in English.

从给定的上下文文本中提取出对回答问题最重要的词（选择尽可能少且重要的词），不需要提供问题的答案，输出
的词与词之间用逗号隔开。
下面是一个例子:
文本：
2016年9月29日06时25分发布暴雨蓝色预警信号:预计未来12小时内我县大部分地方雨量将达50毫米以上,请注意防
范。
问题：
未来12小时内，我县大部分地方雨量预计会达到多少毫米以上？
重要的词：未来12小时，大部分地方，雨量，50毫米
文本：
问题：
重要的词：

Table 13: Prompts for important word generation in Chinese.

15

User Query:
荷裔澳大利人，是有部分或全部荷人血的澳大利人的，他是在荷以外最大的一荷裔族群。威廉·松船于1606年抵澳
大利，他是第一抵澳大利人的荷人，亦是第一抵澳大利人的洲人。另一知名的荷探家阿·塔斯曼，在澳大利史亦
足重，塔斯曼尼州和塔斯曼海都以他的名字命名。据2006年澳大利人口普查，310,089名居民有部分或全部荷人血
，78,927名于荷出生。
知名的澳大利荷人：
克里斯·海姆斯沃斯
卡··莫格。
：根据2006年澳大利人口普查，有部分或全部荷人血的居民量是多少？
Sensitive words and corresponding substitution words:
(澳大利:新西),(威廉·松船:翰·史密斯),(1606年:1612年),(阿·塔斯曼:詹姆斯·布朗),(塔斯曼尼州:多利州),(塔斯曼海:布
里斯班海),(2006年:2010年),(310,089名:285,000名),(78,927名:75,000名),(克里斯·海姆斯沃斯:托斯·哈里森),(卡··莫格:克
·威)
Substituted Query:
荷裔新西人，是有部分或全部荷人血的新西人的，他是在荷以外最大的一荷裔族群。翰·史密斯于1612年抵新西，
他是第一抵新西人的荷人，亦是第一抵新西人的洲人。另一知名的荷探家詹姆斯·布朗，在新西史亦足重，多利州
和布里斯班海都以他的名字命名。据2010年新西人口普查，285,000名居民有部分或全部荷人血，75,000名于荷出
生。
知名的新西荷人
托斯·哈里森
克·威。
：根据2010年新西人口普查，有部分或全部荷人血的居民量是多少
Obfuscated Query:
荷裔新西人，是薿部分或全部荷人血新西人的，翷是在荷以外最大的一荷裔族群。翰·史密斯于1612年抵新西，他
是第一抵新西人的荷人，亦是第一抵新西人的洲人。另一萳荷探家詹姆斯·布朗，在新西史亦足重，多利州和布里
斯班海都以他的名字命名。据2010年新西人口普查，285,000名居民有部分或全部荷人血，75,000名于荷出生。
新西荷人
托斯·哈里森
克·威。
：根据2010年新西人口普查，有部分或全部荷人血的居民量是多少？
Cloud LLM Response:
根据2010年新西人口普查，有部分或全部荷人血的居民量是285,000名。
Recovered Response:
根据2006年澳大利人口普查，有部分或全部荷人血的居民量是310,089名。

Table 14: An example for our pipeline in Chinese.

16

User Query:
In the bustling streets of [City], Nikolai Cao, a seasoned carpenter with a reputation for meticulous craftsmanship, embarked on
a project that would showcase his dedication to excellence. The undertaking involved transforming an ordinary room into a
haven of tranquility and functionality. Nikolai’s phone buzzed, displaying an incoming call from 0502 4282799. It was Mr.
Davies, the homeowner, eager to discuss the project details. With a warm smile, Nikolai listened attentively, absorbing Mr.
Davies’ vision for the space. Drawing upon his years of experience, Nikolai proposed a comprehensive plan that encompassed
every aspect of the renovation. He envisioned a room bathed in natural light, where every piece of furniture served a purpose
and harmonized seamlessly with the overall aesthetic. Nikolai’s email inbox pinged, a message from nikolai_cao@yahoo.com
arrived. It contained detailed sketches and renderings of the proposed design. Mr. Davies was thrilled with Nikolai’s creativity
and attention to detail. They scheduled a meeting to finalize the project timeline and budget. With the plans set in motion,
Nikolai immersed himself in the task. He carefully selected each piece of material, ensuring they met his exacting standards.
From the warm hues of the hardwood flooring to the intricate carvings adorning the custom-built cabinetry, every element
reflected Nikolai’s commitment to quality. Days turned into weeks as Nikolai meticulously brought his vision to life. He
worked tirelessly, transforming the room into a sanctuary of comfort and style. The room exuded an aura of timeless elegance,
with subtle hints of modern sophistication. The project’s completion marked a proud moment for Nikolai. He had successfully
crafted a space that not only met Mr. Davies’ expectations but also exceeded them. The room had become a haven where Mr.
Davies could relax, recharge, and find inspiration. As Nikolai handed over the keys to Mr. Davies, a sense of accomplishment
washed over him. He knew that his hard work and dedication had created something truly special. Mr. Davies’ heartfelt
gratitude and satisfaction were the ultimate testament to Nikolai’s unwavering commitment to excellence. Question: What
elements in the room design reflect Nikolai’s commitment to quality and craftsmanship?
Sensitive words and corresponding substitution words:
(Nikolai Cao:Alexei Tran),(Nikolai:Alexei),(0502 4282799:0123 4567890),
(Mr. Davies:Dr. Lewis),(nikolai_cao@yahoo.com:alexei_tran@outlook.com)
Substituted Query:
In the bustling streets of [City], Alexei Tran, a seasoned carpenter with a reputation for meticulous craftsmanship, embarked
on a project that would showcase his dedication to excellence. The undertaking involved transforming an ordinary room into
a haven of tranquility and functionality. Alexei’s phone buzzed, displaying an incoming call from 0123 4567890. It was Dr.
Lewis, the homeowner, eager to discuss the project details. With a warm smile, Alexei listened attentively, absorbing Dr. Lewis’
vision for the space. Drawing upon his years of experience, Alexei proposed a comprehensive plan that encompassed every
aspect of the renovation. He envisioned a room bathed in natural light, where every piece of furniture served a purpose and
harmonized seamlessly with the overall aesthetic. Alexei’s email inbox pinged, a message from alexei_tran@outlook.com
arrived. It contained detailed sketches and renderings of the proposed design. Dr. Lewis was thrilled with Alexei’s creativity
and attention to detail. They scheduled a meeting to finalize the project timeline and budget. With the plans set in motion,
Alexei immersed himself in the task. He carefully selected each piece of material, ensuring they met his exacting standards.
From the warm hues of the hardwood flooring to the intricate carvings adorning the custom-built cabinetry, every element
reflected Alexei’s commitment to quality. Days turned into weeks as Alexei meticulously brought his vision to life. He worked
tirelessly, transforming the room into a sanctuary of comfort and style. The room exuded an aura of timeless elegance, with
subtle hints of modern sophistication. The project’s completion marked a proud moment for Alexei. He had successfully crafted
a space that not only met Dr. Lewis’ expectations but also exceeded them. The room had become a haven where Dr. Lewis
could relax, recharge, and find inspiration. As Alexei handed over the keys to Dr. Lewis, a sense of accomplishment washed
over him. He knew that his hard work and dedication had created something truly special. Dr. Lewis’ heartfelt gratitude and
satisfaction were the ultimate testament to Alexei’s unwavering commitment to excellence. Question: What elements in the
room design reflect Alexei’s commitment to quality and craftsmanship?
Obfuscated Query:
theory aspect owl even cloud Alexei Tran answer ASS point ruption do Option ta medic might IT These known Those fighting
partial teacher later ai resume do or effect lose de agent sit resp 0123 4567890 taste cam Dr. Lewis shall dont assess BACK
CODE us ere wide sale i Dr. Lewis awa fore Div detailed nearby He they scene antes ura visible were If herself length Whether
toBe hero Override ester tan ember natural light Ar her however po furniture bow purpose Also harmonized Ide appear finished
aesthetic edit ARY thing instead fourth alexei_tran@outlook.com tank extended checked handler NOT study scheme Dr. Lewis
then post example And pet may credit Any H community to social edge AN balance for stud sol cope truck witch yourself
oes termin people HE HER err ago horse do border di dig She hot eu props zo May Was hit hardwood flooring shall their
Clear alpha error toggle custom-built cabinetry any material ire implementation not Review protein intent ens ever gas hers
relationship who second basically Run di hood From AGE have critic viron philosoph hist Level els Yet may vary If Mad exam
identity completion developer ga strange instead kan Her making Lesser Solution ST unless across fun vill Dr. Lewis attorney
THE them Most walking salt operating Application corresponding cut Dr. Lewis well slowly reet offer Cast rib Offset employee
when Dr. Lewis awa scenario they ordinate seriously You correctly tot this Friend leg ey university skin largely colour Dr.
Lewis and exam plenty may bug contact beQuestion: What elements in the room design reflect Alexei’s commitment to quality
and craftsmanship?
Cloud LLM Response:
The elements in the room design that reflect Alexei’s commitment to quality and craftsmanship include the natural light,
purposeful and harmonious furniture, hardwood flooring, and custom-built cabinetry with intricate carvings.
Recovered Response:
The elements in the room design that reflect Nikolai’s commitment to quality and craftsmanship include the natural light,
purposeful and harmonious furniture, hardwood flooring, and custom-built cabinetry with intricate carvings.

Table 15: An example for our pipeline in English.

17

Please act as an impartial judge and evaluate the quality of the responses provided by two AI assistants to the user question
displayed below. You should choose the assistant that follows the user’s instructions and answers the user’s question better
according to the text given. Your evaluation should consider factors such as the correctness of answers, accuracy, relevance and
reasonableness of their responses. If both responses give the correct answers based on the text, you are welcome to give a tie.
Begin your evaluation by comparing the two responses and provide a short explanation. Avoid any position biases and ensure
that the order in which the responses were presented does not influence your decision. Do not allow the length of the responses
to influence your evaluation. Do not favor certain names of the assistants. Be as objective as possible. After providing your
explanation, output your final verdict by strictly following this format: "[[A]]" if assistant A is better, "[[B]]" if assistant B is
better, and "[[C]]" for a tie.
[Given Text]
{text}
[User Question]
{question}
[The Start of Assistant A’s Answer]
{answer_a}
[The End of Assistant A’s Answer]
[The Start of Assistant B’s Answer]
{answer_b}
[The End of Assistant B’s Answer]

Table 16: GPT-4 Judeg Prompt.

Prompt for generating English open-ended questions:
The above is a given text. Propose 2 questions based on the above text, ensuring that the answers can be summarized, inferred,
or deduced solely from the information in the text.
Questions:
Prompt for generating open-ended Chinese questions:
以上是一段给定的文本，作为一个出题者，针对上述报道，提出2个问题，使该问题的答案一定可以由上述文本中
的信息总结、归纳、或推理得出。
问题
以上是一段给定的文本，作为一个出题者，你能否基于上述报道，引申出2个开放性问题，使该问题中的信息都来
自于上述文本，但回答者无法直接基于上述文本内容得出确定的答案。
问题：
Prompt for generating English information extraction questions:
The above is a given text that contains a word related to sensitivity and privacy {cur_sensitive}.
Based on the text above, propose one question such that the answer can be inferred from the text as {cur_sensitive}.
Question:
Prompt for generating Chinese information extraction questions:
以上是一段给定的文本，该段文本中有一个涉及敏感与隐私的词语{cur_sensitive}，结合上述文本，提出1个问题，
使该问题的答案可以由上述文本归纳得到为{cur_sensitive}。
问题：

Table 17: Question generation prompt.

18

