#!/usr/bin/env python3
"""
Analyze the epsilon comparison results to understand how old vs new methods perform
across different epsilon values.
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

def load_epsilon_results(filename):
    """Load the epsilon comparison results from JSON file."""
    with open(filename, 'r') as f:
        return json.load(f)

def analyze_epsilon_sensitivity(results):
    """Analyze how epsilon affects the selection behavior of both methods."""
    print("üî¨ EPSILON SENSITIVITY ANALYSIS")
    print("=" * 60)
    
    epsilon_values = results['epsilon_values']
    questions = results['questions']
    
    # Collect data for analysis
    old_similarities_by_epsilon = {eps: [] for eps in epsilon_values}
    new_similarities_by_epsilon = {eps: [] for eps in epsilon_values}
    old_candidate_ranges_by_epsilon = {eps: [] for eps in epsilon_values}
    new_candidate_ranges_by_epsilon = {eps: [] for eps in epsilon_values}
    
    for question_data in questions:
        question_text = question_data['question_text']
        print(f"\nüìù Question: {question_text}")
        
        for eps_test in question_data['epsilon_tests']:
            if 'error' not in eps_test:
                epsilon = eps_test['epsilon']
                
                # Selected similarities
                old_sim = eps_test['old_method']['similarity_to_original']
                new_sim = eps_test['new_method']['similarity_to_original']
                
                # Candidate diversity (range)
                old_candidates = eps_test['old_method']['candidate_similarities']
                new_candidates = eps_test['new_method']['candidate_similarities']
                old_range = max(old_candidates) - min(old_candidates) if old_candidates else 0
                new_range = max(new_candidates) - min(new_candidates) if new_candidates else 0
                
                old_similarities_by_epsilon[epsilon].append(old_sim)
                new_similarities_by_epsilon[epsilon].append(new_sim)
                old_candidate_ranges_by_epsilon[epsilon].append(old_range)
                new_candidate_ranges_by_epsilon[epsilon].append(new_range)
                
                print(f"  Œµ={epsilon}: Old={old_sim:.3f}, New={new_sim:.3f} | Old_range={old_range:.3f}, New_range={new_range:.3f}")
    
    # Calculate statistics
    print(f"\nüìä STATISTICAL ANALYSIS")
    print("=" * 60)
    
    for epsilon in epsilon_values:
        old_sims = old_similarities_by_epsilon[epsilon]
        new_sims = new_similarities_by_epsilon[epsilon]
        old_ranges = old_candidate_ranges_by_epsilon[epsilon]
        new_ranges = new_candidate_ranges_by_epsilon[epsilon]
        
        print(f"\nŒµ = {epsilon}:")
        print(f"  Old Method - Mean similarity: {np.mean(old_sims):.3f} ¬± {np.std(old_sims):.3f}")
        print(f"  New Method - Mean similarity: {np.mean(new_sims):.3f} ¬± {np.std(new_sims):.3f}")
        print(f"  Old Method - Mean candidate range: {np.mean(old_ranges):.3f} ¬± {np.std(old_ranges):.3f}")
        print(f"  New Method - Mean candidate range: {np.mean(new_ranges):.3f} ¬± {np.std(new_ranges):.3f}")
        
        # Epsilon sensitivity analysis
        if epsilon > min(epsilon_values):
            prev_eps = epsilon_values[epsilon_values.index(epsilon) - 1]
            old_prev_sims = old_similarities_by_epsilon[prev_eps]
            new_prev_sims = new_similarities_by_epsilon[prev_eps]
            
            old_sensitivity = np.mean(old_sims) - np.mean(old_prev_sims)
            new_sensitivity = np.mean(new_sims) - np.mean(new_prev_sims)
            
            print(f"  Sensitivity (vs Œµ={prev_eps}): Old={old_sensitivity:+.3f}, New={new_sensitivity:+.3f}")
    
    return {
        'old_similarities_by_epsilon': old_similarities_by_epsilon,
        'new_similarities_by_epsilon': new_similarities_by_epsilon,
        'old_candidate_ranges_by_epsilon': old_candidate_ranges_by_epsilon,
        'new_candidate_ranges_by_epsilon': new_candidate_ranges_by_epsilon
    }

def analyze_candidate_diversity(results):
    """Analyze the diversity of candidates generated by both methods."""
    print(f"\nüéØ CANDIDATE DIVERSITY ANALYSIS")
    print("=" * 60)
    
    questions = results['questions']
    
    old_all_ranges = []
    new_all_ranges = []
    old_all_means = []
    new_all_means = []
    
    for question_data in questions:
        question_text = question_data['question_text']
        print(f"\nüìù Question: {question_text}")
        
        for eps_test in question_data['epsilon_tests']:
            if 'error' not in eps_test:
                epsilon = eps_test['epsilon']
                
                old_candidates = eps_test['old_method']['candidate_similarities']
                new_candidates = eps_test['new_method']['candidate_similarities']
                
                old_range = max(old_candidates) - min(old_candidates) if old_candidates else 0
                new_range = max(new_candidates) - min(new_candidates) if new_candidates else 0
                old_mean = np.mean(old_candidates) if old_candidates else 0
                new_mean = np.mean(new_candidates) if new_candidates else 0
                
                old_all_ranges.append(old_range)
                new_all_ranges.append(new_range)
                old_all_means.append(old_mean)
                new_all_means.append(new_mean)
                
                print(f"  Œµ={epsilon}: Old range={old_range:.3f}, New range={new_range:.3f} | Old mean={old_mean:.3f}, New mean={new_mean:.3f}")
    
    print(f"\nüìä OVERALL DIVERSITY STATISTICS")
    print("=" * 60)
    print(f"Old Method - Mean range: {np.mean(old_all_ranges):.3f} ¬± {np.std(old_all_ranges):.3f}")
    print(f"New Method - Mean range: {np.mean(new_all_ranges):.3f} ¬± {np.std(new_all_ranges):.3f}")
    print(f"Old Method - Mean similarity: {np.mean(old_all_means):.3f} ¬± {np.std(old_all_means):.3f}")
    print(f"New Method - Mean similarity: {np.mean(new_all_means):.3f} ¬± {np.std(new_all_means):.3f}")
    
    # Improvement analysis
    range_improvement = np.mean(new_all_ranges) - np.mean(old_all_ranges)
    mean_improvement = np.mean(new_all_means) - np.mean(old_all_means)
    
    print(f"\nüéØ IMPROVEMENT ANALYSIS")
    print("=" * 60)
    print(f"Range improvement: {range_improvement:+.3f} ({range_improvement/np.mean(old_all_ranges)*100:+.1f}%)")
    print(f"Mean similarity change: {mean_improvement:+.3f} ({mean_improvement/np.mean(old_all_means)*100:+.1f}%)")
    
    return {
        'old_ranges': old_all_ranges,
        'new_ranges': new_all_ranges,
        'old_means': old_all_means,
        'new_means': new_all_means
    }

def analyze_epsilon_effectiveness(results):
    """Analyze how effectively epsilon controls the selection behavior."""
    print(f"\n‚ö° EPSILON EFFECTIVENESS ANALYSIS")
    print("=" * 60)
    
    epsilon_values = results['epsilon_values']
    questions = results['questions']
    
    # Calculate correlation between epsilon and selected similarity
    old_eps_sim_pairs = []
    new_eps_sim_pairs = []
    
    for question_data in questions:
        for eps_test in question_data['epsilon_tests']:
            if 'error' not in eps_test:
                epsilon = eps_test['epsilon']
                old_sim = eps_test['old_method']['similarity_to_original']
                new_sim = eps_test['new_method']['similarity_to_original']
                
                old_eps_sim_pairs.append((epsilon, old_sim))
                new_eps_sim_pairs.append((epsilon, new_sim))
    
    # Calculate correlations
    old_eps_values = [pair[0] for pair in old_eps_sim_pairs]
    old_sim_values = [pair[1] for pair in old_eps_sim_pairs]
    new_eps_values = [pair[0] for pair in new_eps_sim_pairs]
    new_sim_values = [pair[1] for pair in new_eps_sim_pairs]
    
    old_correlation = np.corrcoef(old_eps_values, old_sim_values)[0, 1]
    new_correlation = np.corrcoef(new_eps_values, new_sim_values)[0, 1]
    
    print(f"Old Method - Epsilon-Similarity Correlation: {old_correlation:.3f}")
    print(f"New Method - Epsilon-Similarity Correlation: {new_correlation:.3f}")
    
    # Analyze epsilon sensitivity (how much similarity changes with epsilon)
    old_sensitivity = []
    new_sensitivity = []
    
    for i in range(1, len(epsilon_values)):
        prev_eps = epsilon_values[i-1]
        curr_eps = epsilon_values[i]
        
        old_prev_sims = [sim for eps, sim in old_eps_sim_pairs if eps == prev_eps]
        old_curr_sims = [sim for eps, sim in old_eps_sim_pairs if eps == curr_eps]
        new_prev_sims = [sim for eps, sim in new_eps_sim_pairs if eps == prev_eps]
        new_curr_sims = [sim for eps, sim in new_eps_sim_pairs if eps == curr_eps]
        
        if old_prev_sims and old_curr_sims:
            old_sens = np.mean(old_curr_sims) - np.mean(old_prev_sims)
            old_sensitivity.append(old_sens)
        
        if new_prev_sims and new_curr_sims:
            new_sens = np.mean(new_curr_sims) - np.mean(new_prev_sims)
            new_sensitivity.append(new_sens)
    
    print(f"\nOld Method - Average epsilon sensitivity: {np.mean(old_sensitivity):.3f}")
    print(f"New Method - Average epsilon sensitivity: {np.mean(new_sensitivity):.3f}")
    
    return {
        'old_correlation': old_correlation,
        'new_correlation': new_correlation,
        'old_sensitivity': old_sensitivity,
        'new_sensitivity': new_sensitivity
    }

def main():
    """Main analysis function."""
    print("üî¨ EPSILON COMPARISON ANALYSIS")
    print("=" * 80)
    print(f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Load results
    results = load_epsilon_results('epsilon_comparison_results_20250920_144014.json')
    
    # Run analyses
    sensitivity_data = analyze_epsilon_sensitivity(results)
    diversity_data = analyze_candidate_diversity(results)
    effectiveness_data = analyze_epsilon_effectiveness(results)
    
    print(f"\nüéØ FINAL CONCLUSIONS")
    print("=" * 80)
    
    # Overall assessment
    range_improvement = np.mean(diversity_data['new_ranges']) - np.mean(diversity_data['old_ranges'])
    correlation_improvement = effectiveness_data['new_correlation'] - effectiveness_data['old_correlation']
    
    print(f"1. Candidate Diversity:")
    print(f"   - New method shows {range_improvement:+.3f} improvement in candidate range")
    print(f"   - This represents a {range_improvement/np.mean(diversity_data['old_ranges'])*100:+.1f}% improvement")
    
    print(f"\n2. Epsilon Effectiveness:")
    print(f"   - Old method correlation: {effectiveness_data['old_correlation']:.3f}")
    print(f"   - New method correlation: {effectiveness_data['new_correlation']:.3f}")
    print(f"   - Improvement: {correlation_improvement:+.3f}")
    
    print(f"\n3. Overall Assessment:")
    if range_improvement > 0.05 and correlation_improvement > 0.1:
        print("   ‚úÖ NEW METHOD SHOWS SIGNIFICANT IMPROVEMENT")
        print("   - Better candidate diversity")
        print("   - More effective epsilon control")
    elif range_improvement > 0.02:
        print("   ‚ö†Ô∏è  NEW METHOD SHOWS MODEST IMPROVEMENT")
        print("   - Some improvement in candidate diversity")
        print("   - Epsilon effectiveness varies")
    else:
        print("   ‚ùå NEW METHOD SHOWS MINIMAL IMPROVEMENT")
        print("   - Limited improvement in candidate diversity")
        print("   - Epsilon effectiveness similar to old method")

if __name__ == "__main__":
    main()

