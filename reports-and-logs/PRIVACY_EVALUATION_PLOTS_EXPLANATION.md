# Privacy Evaluation Plots Explanation

**Date**: August 26, 2025  
**Dataset**: MedQA (10 Questions)  
**Privacy Parameter**: Œµ=1  
**Methods**: Phrase DP vs InferDPT  

---

## üìä **Generated Plots**

### **1. Comprehensive Plot (`plots/privacy_evaluation_comprehensive.png`)**
A multi-panel visualization showing:
- **Privacy-Utility Trade-off Analysis**
- **Individual Attack Comparison** 
- **Privacy Protection Breakdown**
- **Radar Chart Method Comparison**

### **2. Summary Plot (`plots/privacy_evaluation_summary.png`)**
A simplified two-panel visualization showing:
- **Privacy-Utility Trade-off**
- **Attack Method Comparison**

---

## üîç **Plot Explanations**

### **Privacy-Utility Trade-off Analysis**

**What it shows**: The relationship between privacy protection and accuracy performance.

**Key Findings**:
- **Phrase DP**: High utility (83.91% accuracy) but poor privacy (0.295)
- **InferDPT**: Lower utility (71.20% accuracy) but excellent privacy (0.884)

**Trade-off Zones**:
- **Red Zone (0-0.3)**: Poor Privacy - Easy to recover original questions
- **Orange Zone (0.3-0.6)**: Moderate Privacy - Some protection
- **Green Zone (0.6-1.0)**: Good Privacy - Strong protection

**Insight**: Clear privacy-utility trade-off - better privacy comes at the cost of accuracy.

### **Individual Attack Comparison**

**What it shows**: How each method performs against different types of attacks.

**Attack Methods**:
1. **BERT Inference Attack**: Using BERT embeddings to predict original from perturbed
2. **Embedding Inversion Attack**: Recovering original embeddings from perturbed ones  
3. **GPT Inference Attack**: Using GPT to reconstruct original questions

**Results**:
- **Phrase DP**: Poor performance across all attacks (0.237-0.336)
- **InferDPT**: Excellent performance across all attacks (0.704-0.993)

**Improvement**: InferDPT shows 109-318% improvement over Phrase DP across all attacks.

### **Privacy Protection Breakdown**

**What it shows**: Detailed breakdown of privacy scores by attack method.

**Key Insights**:
- **InferDPT dominates** across all attack methods
- **BERT Attack**: InferDPT achieves 0.993 vs Phrase DP's 0.237 (+318% improvement)
- **Embedding Attack**: InferDPT achieves 0.704 vs Phrase DP's 0.336 (+109% improvement)
- **GPT Attack**: InferDPT achieves 0.955 vs Phrase DP's 0.312 (+209% improvement)

**Privacy Thresholds**:
- **Red Line (0.3)**: Poor Privacy Threshold
- **Orange Line (0.6)**: Moderate Privacy Threshold  
- **Green Line (0.8)**: Good Privacy Threshold

### **Radar Chart Method Comparison**

**What it shows**: Comprehensive comparison of all metrics on a radar/spider chart.

**Metrics Compared**:
1. **Accuracy**: Normalized performance (higher is better)
2. **BERT Privacy**: Protection against BERT attacks
3. **Embedding Privacy**: Protection against embedding inversion
4. **GPT Privacy**: Protection against GPT reconstruction
5. **Overall Privacy**: Combined privacy score

**Visual Pattern**:
- **Phrase DP**: Small area (prioritizes utility)
- **InferDPT**: Large area (prioritizes privacy)

---

## üéØ **Key Insights from the Plots**

### **1. Privacy-Utility Trade-off is Real**
- **Phrase DP**: Prioritizes utility over privacy
- **InferDPT**: Prioritizes privacy over utility
- **No free lunch**: Better privacy comes at accuracy cost

### **2. InferDPT Provides Superior Privacy Protection**
- **199.3% overall improvement** in privacy protection
- **Consistent superiority** across all attack methods
- **Achieves "Excellent" privacy rating** (0.884)

### **3. Attack Method Effectiveness Varies**
- **BERT Attack**: Most challenging for both methods
- **GPT Attack**: InferDPT shows strongest protection
- **Embedding Attack**: Moderate difficulty for both

### **4. Privacy Parameter Impact (Œµ=1)**
- **Œµ=1** represents moderate privacy protection
- **Lower Œµ** would provide stronger privacy but worse utility
- **Higher Œµ** would provide better utility but weaker privacy

---

## üìà **Quantitative Summary**

| Metric | Phrase DP | InferDPT | Improvement |
|--------|-----------|----------|-------------|
| **Overall Privacy** | 0.295 | 0.884 | **+199.3%** |
| **BERT Attack** | 0.237 | 0.993 | **+318%** |
| **Embedding Attack** | 0.336 | 0.704 | **+109%** |
| **GPT Attack** | 0.312 | 0.955 | **+209%** |
| **Accuracy** | 83.91% | 71.20% | **-15.1%** |

---

## üî¨ **Methodological Notes**

### **Evaluation Approach**
- **Follows InferDPT paper methodology**
- **Three attack types** for comprehensive evaluation
- **10 questions** for cost-effective testing
- **Œµ=1** for balanced privacy-utility trade-off

### **Privacy Metrics**
- **Higher scores = Better privacy** (lower recovery accuracy)
- **Range**: 0.0 (no privacy) to 1.0 (perfect privacy)
- **Thresholds**: 0.3 (poor), 0.6 (moderate), 0.8 (good)

### **Statistical Significance**
- **Small sample size** (10 questions) for initial testing
- **Consistent patterns** suggest reliable results
- **Large effect sizes** indicate meaningful differences

---

## üöÄ **Conclusions**

1. **InferDPT provides dramatically better privacy protection** than Phrase DP
2. **Clear privacy-utility trade-off** exists between the methods
3. **Choice depends on application requirements**:
   - **High privacy needed**: Choose InferDPT
   - **High accuracy needed**: Choose Phrase DP
4. **Œµ=1 provides good balance** for most applications
5. **Comprehensive evaluation** confirms InferDPT's superiority across all attack methods

---

*These plots provide visual evidence of the privacy-utility trade-off and demonstrate InferDPT's superior privacy protection capabilities in the MedQA domain.*
